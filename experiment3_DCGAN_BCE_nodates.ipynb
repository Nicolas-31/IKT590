{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, MaxPooling2D, UpSampling2D, Flatten\n",
    "from keras.layers import BatchNormalization, Activation, Conv2D, Conv2DTranspose, Dropout, Reshape, Concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    files = os.listdir(path)\n",
    "    x = []\n",
    "    y = []\n",
    "    for file in files: # number of files to go through\n",
    "        im = np.asarray(image.load_img(os.path.join(path, file), target_size=(64,64)))\n",
    "        lb = int(file.split('_')[0])\n",
    "        nlb = np.asarray([lb])\n",
    "        x.append(im)\n",
    "        y.append(nlb)\n",
    "    x = np.asarray(x)\n",
    "    y = np.asarray(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train_orig = './Food11_256/training_256_datestamp'\n",
    "path_val_orig = './Food11_256/validation_256_datestamp'\n",
    "path_test_orig = './Food11_256/evaluation_256_datestamp'\n",
    "\n",
    "x_train, y_train = load_dataset(path_train_orig)\n",
    "x_val, y_val = load_dataset(path_val_orig)\n",
    "x_test, y_test  = load_dataset(path_test_orig)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(input_layer):\n",
    "\n",
    "    hid = Dense(128 * 16 * 16, activation='relu')(input_layer)    \n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "    hid = Reshape((16, 16, 128))(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=5, strides=1,padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)    \n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2DTranspose(128, 4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=5, strides=1, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2D(3, kernel_size=5, strides=1, padding=\"same\")(hid)\n",
    "    out = Activation(\"tanh\")(hid)\n",
    "\n",
    "    model = Model(input_layer, out)\n",
    "    model.summary()\n",
    "\n",
    "    return model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discriminator(input_layer):\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=3, strides=1, padding='same')(input_layer)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "\n",
    "    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "    \n",
    "    hid = Conv2D(128, kernel_size=4, strides=2, padding='same')(hid)\n",
    "    hid = BatchNormalization(momentum=0.9)(hid)\n",
    "    hid = LeakyReLU(alpha=0.1)(hid)\n",
    "    \n",
    "    hid = Flatten()(hid)\n",
    "    hid = Dropout(0.4)(hid)\n",
    "    out = Dense(1, activation='sigmoid')(hid)\n",
    "\n",
    "    model = Model(input_layer, out)\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_noise(n_samples, noise_dim):\n",
    "    X = np.random.normal(0, 1, size=(n_samples, noise_dim))\n",
    "    return X\n",
    "\n",
    "def show_imgs(batchidx):\n",
    "    noise = generate_noise(9, 100)\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    fig, axs = plt.subplots(3, 3)\n",
    "    count = 0\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            img = image.array_to_img(gen_imgs[count], scale=True)\n",
    "            axs[i,j].imshow(img)\n",
    "            axs[i,j].axis('off')\n",
    "            count += 1\n",
    "    plt.show()\n",
    "    plt.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN creation\n",
    "img_input = Input(shape=(64,64,3))\n",
    "discriminator, disc_out = get_discriminator(img_input)\n",
    "discriminator.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "noise_input = Input(shape=(100,))\n",
    "generator, gen_out = get_generator(noise_input)\n",
    "\n",
    "gan_input = Input(shape=(100,))\n",
    "x = generator(gan_input)\n",
    "gan_out = discriminator(x)\n",
    "gan = Model(gan_input, gan_out)\n",
    "gan.summary()\n",
    "\n",
    "gan.compile(optimizer=Adam(0.0002, 0.5), loss='binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data argumentation\n",
    "def flipp(x):\n",
    "    f = []\n",
    "    for i in x:\n",
    "        m = (np.flip(i,1))\n",
    "        f.append(i)\n",
    "        f.append(m)\n",
    "    return np.asarray(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# # Get training images\n",
    "x_all = np.concatenate((x_train, x_val, x_test))\n",
    "y_all = np.concatenate((y_train, y_val, y_test))\n",
    "\n",
    "# Select a class\n",
    "tags = ['Bread', 'Dairy', 'Dessert', 'Egg', 'Fried Food', 'Meat', 'Noodles', 'Rice', 'Seafood', 'Soup', 'Fruit/Veg']\n",
    "selected_class = 0\n",
    "print(tags[selected_class])\n",
    "x_data = x_all[y_all[:,0]==selected_class]\n",
    "# x_data = flipp(x_data)\n",
    "print (\"Training shape: {}\".format(x_data.shape))\n",
    "\n",
    "# Normalize data\n",
    "x_data = (x_data - 127.5) / 127.5\n",
    "\n",
    "# Check number of files for each category\n",
    "# unique, counts = np.unique(y_all, return_counts=True)\n",
    "# print(dict(zip(unique, counts)))\n",
    "\n",
    "num_batches = int(x_data.shape[0]/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    cum_d_loss = 0.\n",
    "    cum_g_loss = 0.\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        # Get the next set of real images to be used in this iteration\n",
    "        images = x_data[batch_idx*BATCH_SIZE : (batch_idx+1)*BATCH_SIZE]\n",
    "\n",
    "        noise_data = generate_noise(BATCH_SIZE, 100)\n",
    "        generated_images = generator.predict(noise_data)\n",
    "\n",
    "        # Train on soft labels (add noise to labels as well)\n",
    "        noise_prop = 0.05 # Randomly flip 5% of labels\n",
    "\n",
    "        # Prepare labels for real data\n",
    "        true_labels = np.zeros((BATCH_SIZE, 1)) + np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n",
    "        flipped_idx = np.random.choice(np.arange(len(true_labels)), size=int(noise_prop*len(true_labels)))\n",
    "        true_labels[flipped_idx] = 1 - true_labels[flipped_idx]\n",
    "\n",
    "        # Train discriminator on real data\n",
    "        discriminator.trainable = True\n",
    "        d_loss_true = discriminator.train_on_batch(images, true_labels)\n",
    "\n",
    "        # Prepare labels for generated data\n",
    "        gene_labels = np.ones((BATCH_SIZE, 1)) - np.random.uniform(low=0.0, high=0.1, size=(BATCH_SIZE, 1))\n",
    "        flipped_idx = np.random.choice(np.arange(len(gene_labels)), size=int(noise_prop*len(gene_labels)))\n",
    "        gene_labels[flippen = 9\n",
    "samples = np.asarray(random_subset(x_test, n))\n",
    "predictions = autoencoder.predict(samples)\n",
    "show_samples(samples,predictions,n)d_idx] = 1 - gene_labels[flipped_idx]\n",
    "\n",
    "        # Train discriminator on generated data\n",
    "        d_loss_gene = discriminator.train_on_batch(generated_images, gene_labels)\n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_true, d_loss_gene)\n",
    "        cum_d_loss += d_loss\n",
    "        discriminator.trainable = False\n",
    "\n",
    "        # Train generator\n",
    "        noise_data = generate_noise(BATCH_SIZE, 100)\n",
    "        g_loss = gan.train_on_batch(noise_data, np.zeros((BATCH_SIZE, 1)))\n",
    "        cum_g_loss += g_loss\n",
    "\n",
    "    print(' Epoch: {}, Generator Loss: {}, Discriminator Loss: {}'.format(epoch+1, cum_g_loss/num_batches, cum_d_loss/num_batches))\n",
    "    show_imgs(\"epoch\" + str(epoch))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
